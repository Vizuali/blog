{"componentChunkName":"component---src-templates-blog-post-js","path":"/documentation/","result":{"data":{"site":{"siteMetadata":{"title":"Visual Computing 2020"}},"mdx":{"id":"a94f16c6-55fe-5981-91b1-0d6f262a278b","excerpt":"This page contains the documentation of the image processing workshop. Motivation Almost all the explanations in the course where given in processing, so weâ€¦","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Documentation\",\n  \"date\": \"2020-06-16T16:00:00.0000\",\n  \"description\": \"Documentation of the project.\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This page contains the documentation of the image processing workshop.\"), mdx(\"h2\", null, \"Motivation\"), mdx(\"p\", null, \"Almost all the explanations in the course where given in processing, so we wanted to implement the image procesisng workshop in a web blog in Gatsby using p5.js.\"), mdx(\"h2\", null, \"Objective\"), mdx(\"p\", null, \"To implement the different image processing techniques like convolution masks, grayscale, ascii, etc, with a software and hardware approach.\"), mdx(\"h2\", null, \"Methodology\"), mdx(\"h3\", null, \"Ascii\"), mdx(\"p\", null, \"We calculate the brightness of each pixel and assign a similar character to the pixel. \"), mdx(\"h3\", null, \"Grayscale\"), mdx(\"p\", null, \"We implemented 5 different masks for greyscale:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The first method consists in calculate the average rgb of each pixel an set those (rgb) to the calculated average.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The second method is Luma 601 which uses this function in the average calculation:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/7abe41a6e7496f32b50c658ff646cc51e8495366\",\n    \"alt\": \"alt text\",\n    \"title\": \"Luma 601\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The third method is Luma 709 which uses this function in the average calculation:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/e26a409021fcb5ae8429adc475a7f426f83e7f7a\",\n    \"alt\": \"alt text\",\n    \"title\": \"Luma 709\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The fourth method is Luma 240 which uses this function in the average calculation:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/2714d2c89f12a32700f6cf88e318d887a85b9e20\",\n    \"alt\": \"alt text\",\n    \"title\": \"Luma 240\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The fifth method is Luma 2020 which uses this function in the average calculation:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://i.ibb.co/k12MHyT/Code-Cogs-Eqn.png\",\n    \"alt\": \"alt text\",\n    \"title\": \"Luma 2020\"\n  }))), mdx(\"h3\", null, \"Convolution masks\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Identity\")), mdx(\"p\", null, \"As the name says, the identity matrix is used for this mask:\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/1fbc763a0af339e3a3ff20af60a8a993c53086a7\",\n    \"alt\": \"alt text\",\n    \"title\": \"Edge 1\"\n  }))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Edge detection\")), mdx(\"p\", null, \"We implemented 3 different masks for edge detection. This methods are applied using kernel convolution:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The first method uses the following matrix:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/99a928198c80a46e8c3da70714400f77f6747801\",\n    \"alt\": \"alt text\",\n    \"title\": \"Edge 1\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The second method uses the following matrix:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/1445b36fef5ec4ca0e0b5d7e200c90afaf6af58b\",\n    \"alt\": \"alt text\",\n    \"title\": \"Edge 2\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The third method uses the following matrix:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/f800ad5f76b6c26c729ff0c1fef44284d7cade7a\",\n    \"alt\": \"alt text\",\n    \"title\": \"Edge 3\"\n  }))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Blur effect\")), mdx(\"p\", null, \"For the blur effect, we use two methods:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The box blur:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/91256bfeece3344f8602e288d445e6422c8b8a1c\",\n    \"alt\": \"alt text\",\n    \"title\": \"Boxblur\"\n  }))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Gaussian blur 5x5:\")), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/f91401a3e97428f14862afa1c781c55f4157580b\",\n    \"alt\": \"alt text\",\n    \"title\": \"Gaussian blur 5x5\"\n  }))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sharpen effect\")), mdx(\"p\", null, \"The following matrix is used:\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"https://wikimedia.org/api/rest_v1/media/math/render/svg/beb8b9a493e8b9cf5deccd61bd845a59ea2e62cc\",\n    \"alt\": \"alt text\",\n    \"title\": \"Sharpen\"\n  }))), mdx(\"h2\", null, \"Results\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ascii\")), mdx(\"p\", null, \"We got a very fluent live video, the fps rate depends on the hardware of the user, so in low end devices the framerate can be lower.\\nThe lag on the video is mostly because of the camera used.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolution Maks\")), mdx(\"p\", null, \"The sharpen and edge detection masks work very fast, as we can see in the video processing entry. However, the Blur mask work slower\\non images but fast on video processing. This maybe has something to do with the hardware or the Web Browser. The gray effects were fast\\non both, image and video, very fast.\\nIt goes without saying that the results of the convolution maks were as expected. Actually, we had implementations of the maks in processing\\nbeforehand so the work was focused in the implementation of shaders in p5js. There were problems with the version of WEBGL\\nbut were solved.\"), mdx(\"h2\", null, \"Conclusion\"), mdx(\"p\", null, \"After working on p5js in a web blog, we determined that is powerful as processing when it comes to convolution masks. The capability\\nof run the convolutions in a easy way in Javascript is perfect for newlearners. \"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Documentation","date":"June 16, 2020","description":"Documentation of the project."}}},"pageContext":{"slug":"/documentation/","previous":{"fields":{"slug":"/grayscale-shader/"},"frontmatter":{"title":"Gray Scale: I just see two colors :o (Hardware)"}},"next":null}}}